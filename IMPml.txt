
/////////////////////////////////////////////////////////////////
BT
/////////////////////////////////////////////////////////////////

Expt1:



import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import datetime as dt

df = pd.read_csv("uber.csv")
df.head()

df.drop(columns=['Unnamed: 0','key'],inplace=True)

df.info()

df.dropna(how='any',inplace=True)

df.isnull().sum()

for col in df.select_dtypes(exclude=['object']):
plt.figure()
sns.boxplot(data=df,x=col)

df = df[
(df.pickup_latitude > -90) & (df.pickup_latitude < 90) &
(df.dropoff_latitude > -90) & (df.dropoff_latitude < 90) &
(df.pickup_longitude > -180) & (df.pickup_longitude < 180) &
(df.dropoff_longitude > -180) & (df.dropoff_longitude < 180) &
(df.fare_amount > 0) & (df.passenger_count > 0) & (df.passenger_co
]

from math import cos, asin, sqrt, pi
import numpy as np
​
def distance(lat_1,lon_1,lat_2,lon_2):
#
lat1 = row.pickup_latitude
#
lon1 = row.pickup_longitude
#
lat2 = row.dropoff_latitude
#
lon2 = row.dropoff_longitude
lon_1, lon_2, lat_1, lat_2 = map(np.radians, [lon_1, lon_2, lat_1,
diff_lon = lon_2 - lon_1
diff_lat = lat_2 - lat_1
​
km = 2 * 6371 * np.arcsin(np.sqrt(np.sin(diff_lat/2.0)**2 +
np.cos
return km

temp = distance(df['pickup_latitude'],df['pickup_longitude'],df['dropof
temp.head()

df_new = df.copy()
df_new['Distance'] = temp
df = df_new
df.head()

sns.boxplot(data=df,x='Distance')

df = df[(df['Distance'] < 200) & (df['Distance'] > 0)]

df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])

df['week_day'] = df['pickup_datetime'].dt.day_name()
df['Year'] = df['pickup_datetime'].dt.year
df['Month'] = df['pickup_datetime'].dt.month
df['Hour'] = df['pickup_datetime'].dt.hour

df.drop(columns=['pickup_datetime','pickup_latitude','pickup_longit
ude','dropoff_latitude','dropoff_longitude'],inplace=True)

df.head()

temp = df.copy()
​
def convert_week_day(day):
if day in ['Monday','Tuesday','Wednesday','Thursday']:
return 0 # Weekday
return 1 # Weekend
​
def convert_hour(hour):
if 5 <= hour <= 12:
return 1
elif 12 < hour <= 17:
return 2
elif 17 < hour < 24:
return 3
return 0
​
df['week_day'] = temp['week_day'].apply(convert_week_day)
df['Hour'] = temp['Hour'].apply(convert_hour)
df.head()

df.corr()

sns.scatterplot(y=df['fare_amount'],x=df['Distance'])

from sklearn.preprocessing import StandardScaler
x = df[['Distance']].values
y = df['fare_amount'].values.reshape(-1,1)

from sklearn.model_selection import train_test_split
x_train, x_test, y_train,y_test = train_test_split(x,y,random_state=10)

std_x = StandardScaler()
x_train = std_x.fit_transform(x_train)

x_test = std_x.transform(x_test)

std_y = StandardScaler()
y_train = std_y.fit_transform(y_train)

y_test = std_y.transform(y_test)

from sklearn.metrics import mean_squared_error,r2_score, mean_absolute_
def fit_predict(model):
model.fit(x_train,y_train.ravel())
y_pred = model.predict(x_test)
r_squared = r2_score(y_test,y_pred)
RMSE = mean_squared_error(y_test, y_pred,squared=False)
MAE = mean_absolute_error(y_test,y_pred)
print('R-squared: ', r_squared)
print('RMSE: ', RMSE)
print("MAE: ",MAE)

from sklearn.linear_model import LinearRegression

fit_predict(LinearRegression())

from sklearn.ensemble import RandomForestRegressor
fit_predict(RandomForestRegressor())

/////////////////////////////////////////////////////////

expt 2


import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('emails.csv')
df.head()

df.isnull().sum()

df.dropna(how='any',inplace=True)

x = df.iloc[:,1:-1].values
y = df.iloc[:,-1].values

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=10)

from sklearn.metrics import ConfusionMatrixDisplay,confusion_matrix,accuracy_score,precision_score,recall_scor
def report(classifier):
y_pred = classifier.predict(x_test)
cm = confusion_matrix(y_test,y_pred)
display = ConfusionMatrixDisplay(cm,display_labels=classifier.classes_)
display.plot()
print(f"Accuracy: {accuracy_score(y_test,y_pred)}")
print(f"Precision Score: {precision_score(y_test,y_pred)}")
print(f"Recall Score: {recall_score(y_test,y_pred)}")

from sklearn.neighbors import KNeighborsClassifier

kNN = KNeighborsClassifier(n_neighbors=10)
kNN.fit(x_train,y_train)

report(kNN)

from sklearn.svm import SVC
svm = SVC(gamma='auto',random_state=10)
svm.fit(x_train,y_train)

report(svm)


////////////////////////////////////////////////////////////////
Expt 3:

import numpy as np
import pandas as pd
import sympy as sym
import matplotlib as pyplot
from matplotlib import pyplot

def objective(x):
return (x+3)**2

def derivative(x):
return 2*(x+3)

def gradient(alpha,start,max_iter):
x_list=list()
x=start
x_list.append(x)
for i in range(max_iter):
gradi=derivative(x)
x=x-(alpha*gradi)
x_list.append(x)
return x_list
x=sym.symbols('x')
expr=(x+3)**2.0
grad=sym.Derivative(expr,x)
print("{}".format(grad.doit()))
grad.doit().subs(x,2)

alpha=0.1
start=2
max_iter=30
x=sym.symbols('x')
expr=(x+3)**2

x_cor=np.linspace(-15,15,100)
pyplot.plot(x_cor,objective(x_cor))
pyplot.plot(2,objective(2),'ro')

x=gradient(alpha,start,max_iter)
x_cor=np.linspace(-5,5,100)
pyplot.plot(x_cor,objective(x_cor))
​
x_arr=np.array(x)
pyplot.plot(x_arr,objective(x_arr),'.-',color='red')
pyplot.show()

//////////////////////////////////////////////////////////////
expt4:

import numpy as np
import pandas as pd



data = pd.read_csv('./diabetes.csv')
data.head()

#Check for null or missing values
data.isnull().sum(

#Replace zero values with mean values
for column in data.columns[1:-3]:
data[column].replace(0, np.NaN, inplace = True)
data[column].fillna(round(data[column].mean(skipna=True)), inplace
data.head(10)

X = data.iloc[:, :8] #Features
Y = data.iloc[:, 8:] #Predictor

#Perform Spliting
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2

#KNN
from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier()
knn_fit = knn.fit(X_train, Y_train.values.ravel())
knn_pred = knn_fit.predict(X_test)

from sklearn.metrics import confusion_matrix, precision_score, recall_s
print("Confusion Matrix")
print(confusion_matrix(Y_test, knn_pred))
print("Accuracy Score:", accuracy_score(Y_test, knn_pred))
print("Reacal Score:", recall_score(Y_test, knn_pred))
print("F1 Score:", f1_score(Y_test, knn_pred))
print("Precision Score:",precision_score(Y_test, knn_pred))
print("Error Rate:",(1-accuracy_score(Y_test, knn_pred)))


///////////////////////////////////////////////////////////////////expt 5

import pandas as pd
import numpy as np

df = pd.read_csv('sales_data_sample.csv', encoding='unicode_escape')
df.head

df.info

#Columns to Remove
to_drop = ['ADDRESSLINE1', 'ADDRESSLINE2', 'STATE', 'POSTALCODE', 'PHONE']
df = df.drop(to_drop, axis=1)

#Check for null values
df.isnull().sum(

df.dtypes

#ORDERDATE Should be in date time
df['ORDERDATE'] = pd.to_datetime(df['ORDERDATE'])

#We need to create some features in order to create cluseters
#Recency: Number of days between customer's latest order and today's date
#Frequency : Number of purchases by the customers
#MonetaryValue : Revenue generated by the customers
import datetime as dt
snapshot_date = df['ORDERDATE'].max() + dt.timedelta(days = 1)
df_RFM = df.groupby(['CUSTOMERNAME']).agg({
'ORDERDATE' : lambda x : (snapshot_date - x.max()).days,
'ORDERNUMBER' : 'count',
'SALES' : 'sum'
})


#Rename the columns
df_RFM.rename(columns = {
'ORDERDATE' : 'Recency',
'ORDERNUMBER' : 'Frequency',
'SALES' : 'MonetaryValue'
}, inplace=True

df_RFM.head()

# Divide into segments
# We create 4 quartile ranges
df_RFM['M'] = pd.qcut(df_RFM['MonetaryValue'], q = 4, labels = range(1,5))
df_RFM['R'] = pd.qcut(df_RFM['Recency'], q = 4, labels = list(range(4,0,-1)))
df_RFM['F'] = pd.qcut(df_RFM['Frequency'], q = 4, labels = range(1,5))
df_RFM.head()


#Create another column for RFM score
df_RFM['RFM_Score'] = df_RFM[['R', 'M', 'F']].sum(axis=1)
df_RFM.head()

def rfm_level(df):
if bool(df['RFM_Score'] >= 10):
return 'High Value Customer'
elif bool(df['RFM_Score'] < 10) and bool(df['RFM_Score'] >= 6):
return 'Mid Value Customer'
else:
return 'Low Value Customer'
df_RFM['RFM_Level'] = df_RFM.apply(rfm_level, axis = 1)
df_RFM.head()


# Time to perform KMeans
data = df_RFM[['Recency', 'Frequency', 'MonetaryValue']]
data.head()


# Our data is skewed we must remove it by performing log transformation
data_log = np.log(data)
data_log.head()

#Standardization
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaler.fit(data_log)
data_normalized = scaler.transform(data_log)
data_normalized = pd.DataFrame(data_normalized, index = data_log.index, columns=dat
data_normalized.describe().round(2)


import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
sse = {}
for k in range(1, 21):
kmeans = KMeans(n_clusters = k, random_state = 1)
kmeans.fit(data_normalized)
sse[k] = kmeans.inertia_


plt.figure(figsize=(10,6))
plt.title('The Elbow Method')
plt.xlabel('K')
plt.ylabel('SSE')
plt.style.use('ggplot')
sns.pointplot(x=list(sse.keys()), y = list(sse.values()))
plt.text(4.5, 60, "Largest Angle", bbox = dict(facecolor = 'lightgreen', alpha = 0.
plt.show()

# 5 number of clusters seems good
kmeans = KMeans(n_clusters=5, random_state=1)
kmeans.fit(data_normalized)
cluster_labels = kmeans.labels_
data_rfm = data.assign(Cluster = cluster_labels)
data_rfm.head()

